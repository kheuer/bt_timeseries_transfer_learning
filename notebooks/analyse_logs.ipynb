{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/koos/Documents/timeseries_transfer_learning'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.getcwd()[-9:] == \"notebooks\":\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_list(lst):\n",
    "    lst = np.array(lst)\n",
    "    min_value = min(lst)\n",
    "    max_value = max(lst)\n",
    "    if min_value == max_value:\n",
    "        return lst, (min_value, max_value)\n",
    "    else:\n",
    "        return list(((lst - min_value) / (max_value - min_value))), (min_value, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(filepath):\n",
    "    with open(filepath, \"r\") as file:\n",
    "        log = file.read()\n",
    "    log_lst = []\n",
    "    for el in log.split(\"#####################################################\"):\n",
    "        if len(el) > 10:\n",
    "            log_lst.append(el)\n",
    "    logs = []\n",
    "    for el in log_lst:\n",
    "        logs.append([])\n",
    "        sub_elms = el.split(\"\\n\")\n",
    "\n",
    "        extracted_content = re.search(r\"\\{.*\\}\", sub_elms[9]).group()\n",
    "        extracted_content = extracted_content.replace(\"'\", \"\\\"\")\n",
    "        params_dict = json.loads(extracted_content)\n",
    "\n",
    "            \n",
    "        result_dict = {}\n",
    "\n",
    "        for item in sub_elms[1:9]:\n",
    "            parts = item.split(': ')\n",
    "            key = parts[0].split(' for ')[1].replace('()', '')  # Extracting the key\n",
    "            value = float(parts[1])  # Extracting the numerical value\n",
    "            result_dict[key] = value\n",
    "\n",
    "        logs[-1].append(params_dict) \n",
    "        logs[-1].append(result_dict) \n",
    "    df_builder = []\n",
    "    for key, val in logs:\n",
    "        key.update(val)\n",
    "        df_builder.append(key)\n",
    "\n",
    "    df = pd.DataFrame(df_builder)\n",
    "    return df\n",
    "df_stock = get_df(\"/home/koos/Desktop/optuna_logs/STOCK_DATA_STUDY_1701992411.5544963.txt\")\n",
    "df_all = get_df(\"optuna_logs/ALL_DATA_STUDY_regularization_1704237277.2332232.txt\")\n",
    "df_all_2 = get_df(\"/home/koos/Desktop/optuna_logs/ALL_DATA_STUDY_1702241361.8004432.txt\")\n",
    "\n",
    "df_all[\"enrich_ratio\"] = df_all[\"enrich_ratio\"] / 10\n",
    "df_all_2[\"enrich_ratio\"] = df_all_2[\"enrich_ratio\"] / 10\n",
    "\n",
    "df_stock = df_stock[df_stock[\"L1Loss\"] < 0.1]\n",
    "df_all = df_all[df_all[\"L1Loss\"] < 0.1]\n",
    "df_all_2 = df_all_2[df_all_2[\"L1Loss\"] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [\"MSELoss\", \"HuberLoss\"] #\"L1Loss\", #, \"LastValueError\", \"ArithmetricMeanTotalReturnError\", \"GeometricMeanDailyReturnError\", \"MedianFinalReturnError\"]#, \"OverUnderEstimationError\"]\n",
    "other = \"enrich_ratio\"\n",
    "\n",
    "for other in [\"enrich_ratio\", 'window_size', 'learning_rate', 'num_stacks', 'num_blocks',\n",
    "       'num_layers', 'expansion_coefficient_dimension',\n",
    "       'trend_polynomial_degree', 'layer_widths', 'dropout', 'activation']:\n",
    "    for loss in losses:\n",
    "        sample = df_all.groupby(other)[loss].median().reset_index()\n",
    "        plt.plot(sample[other], sample[loss], label=loss)\n",
    "\n",
    "    plt.title(\"Loss for models with all data\")\n",
    "    plt.xlabel(other)\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock.sort_values(by=\"L1Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.sort_values(by=\"L1Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_2.sort_values(by=\"L1Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = df_stock.sort_values(by=\"L1Loss\").learning_rate.values\n",
    "loss = df_stock.sort_values(by=\"L1Loss\").L1Loss.values\n",
    "plt.scatter(loss, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all_2\n",
    "\n",
    "X = sm.add_constant(df[[\"enrich_ratio\", \"window_size\", \"learning_rate\", \"num_stacks\", \"num_blocks\", \"num_layers\", \"expansion_coefficient_dimension\", \"trend_polynomial_degree\", \"layer_widths\"]])\n",
    "y = df['L1Loss']\n",
    "\n",
    "\n",
    "# Fitting the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
